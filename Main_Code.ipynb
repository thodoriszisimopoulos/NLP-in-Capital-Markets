{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "69DIWRzxF2Pv",
        "QIwVDDITIXMc",
        "hJL5qPz0JrkG",
        "rOMYbo3hKawX",
        "MAkZA2g8VvGr",
        "hxy3vnIjnGx8",
        "m5bx_UBjv35r",
        "vfnbc-ehzSDw",
        "8g0PQIkb3CaT"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "69DIWRzxF2Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "TCZBsbZLeeAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pandas openpyxl sqlalchemy psycopg2-binary flair langchain langchain-community langchain-openai"
      ],
      "metadata": {
        "id": "y_o9igHdF-cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "eV0zHTEDeT23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import List\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "ZfztWIRCeZSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL Connection"
      ],
      "metadata": {
        "id": "QIwVDDITIXMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ],
      "metadata": {
        "id": "n2P80MFRFLiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Excel files in database"
      ],
      "metadata": {
        "id": "hJL5qPz0JrkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Read the uploaded Excel file into a DataFrame\n",
        "file_name = '/content/Mock up book.xls'  # uploaded to colab this will be deleted\n",
        "df = pd.read_excel(file_name)\n",
        "\n",
        "# Upload the DataFrame to PostgreSQL\n",
        "table_name = 'mock_data'\n",
        "df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
        "\n",
        "print(f\"Uploaded {file_name} to {table_name} table in PostgreSQL.\")'''"
      ],
      "metadata": {
        "id": "vQSU5y-VJxSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful functions for querying SQL"
      ],
      "metadata": {
        "id": "rOMYbo3hKawX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists all tables in database\n",
        "def get_all_tables():\n",
        "    query = \"\"\"\n",
        "    SELECT table_name\n",
        "    FROM information_schema.tables\n",
        "    WHERE table_schema = 'public'\n",
        "    \"\"\"\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Lists the columns in a table and their data type\n",
        "def inspect_columns(table_name):\n",
        "    query = f\"\"\"\n",
        "    SELECT column_name, data_type\n",
        "    FROM information_schema.columns\n",
        "    WHERE table_name = '{table_name}'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with engine.connect() as connection:\n",
        "            result = pd.read_sql_query(query, connection)\n",
        "        print(f\"Columns and their data types in the table {table_name}:\\n\")\n",
        "        print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Returns the first 5 rows\n",
        "def get_top_5_rows(table_name):\n",
        "    query = f\"SELECT * FROM {table_name} LIMIT 5\"\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Executes a given query\n",
        "def execute_query(table_name, query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ],
      "metadata": {
        "id": "37U0RdSeKuGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Example usage\n",
        "inspect_columns('mock_data')\n",
        "\n",
        "table_name = 'mock_data'\n",
        "columns = '\"Feedback\"'\n",
        "query = f\"SELECT {columns} FROM {table_name}\"\n",
        "execute_query(table_name, query)\n",
        "'''"
      ],
      "metadata": {
        "id": "4G8wbIhQHZiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "MAkZA2g8VvGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = 'mock_data'\n",
        "columns = '\"Feedback\"'\n",
        "query = f\"SELECT {columns} FROM {table_name}\"\n",
        "df = execute_query(table_name, query)"
      ],
      "metadata": {
        "id": "12BR3EI6MeHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "pOfKxSXBY9Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models import TextClassifier\n",
        "classifier = TextClassifier.load('en-sentiment')\n",
        "# Import flair Sentence to process input text\n",
        "from flair.data import Sentence\n",
        "# Import accuracy_score to check performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "text= df[\"Feedback\"][0]\n",
        "sentence = Sentence(text)\n",
        "classifier.predict(sentence)\n",
        "score = sentence.labels[0].score\n",
        "value = sentence.labels[0].value"
      ],
      "metadata": {
        "id": "W9aWc8fVwrLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score, value"
      ],
      "metadata": {
        "id": "rd0tPaGdv8WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Feedback'][0]"
      ],
      "metadata": {
        "id": "XkMh9efZwAij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgXa_SpFxx7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text 2 SQL"
      ],
      "metadata": {
        "id": "un9EV4FplLmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 1 (Working)"
      ],
      "metadata": {
        "id": "12tfFIDnoZak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Connect to the Database and Obtain Table and Column Names"
      ],
      "metadata": {
        "id": "8bEok3_6Vnuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, MetaData\n",
        "\n",
        "# Database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create an engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Connect to the database and fetch table and column names\n",
        "metadata = MetaData()\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Store table and column names\n",
        "table_columns = {}\n",
        "for table in metadata.tables.values():\n",
        "    table_columns[table.name] = [column.name for column in table.c]\n",
        "\n",
        "# Print table and column names\n",
        "for table, columns in table_columns.items():\n",
        "    print(f\"Table: {table}, Columns: {columns}\")"
      ],
      "metadata": {
        "id": "fy5TlqqhodnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Use NLP to Parse the User Query"
      ],
      "metadata": {
        "id": "qon6z3JKVp5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a pre-trained model for zero-shot classification\n",
        "nlp_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Example categories for intent classification\n",
        "categories = [\"count\", \"retrieve\", \"average\", \"sum\", \"min\", \"max\"]\n",
        "\n",
        "def parse_user_query(question):\n",
        "    intent_result = nlp_model(question, candidate_labels=categories)\n",
        "    intent = intent_result['labels'][0]  # Most likely intent\n",
        "    return intent\n",
        "\n",
        "# Example usage\n",
        "question = \"How many investors are there?\"\n",
        "parsed_intent = parse_user_query(question)\n",
        "print(parsed_intent)"
      ],
      "metadata": {
        "id": "sNKkWfMvSjMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Dynamically Form and Execute SQL Queries"
      ],
      "metadata": {
        "id": "SV-F6GdbV4GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy.sql import text\n",
        "\n",
        "def form_query(parsed_intent, question):\n",
        "    if parsed_intent == \"count\":\n",
        "        for table, columns in table_columns.items():\n",
        "            for column in columns:\n",
        "                if \"investor\" in column.lower():\n",
        "                    query = f'SELECT COUNT(\"{column}\") FROM {table}'\n",
        "                    return query\n",
        "    elif parsed_intent == \"retrieve\":\n",
        "        for table, columns in table_columns.items():\n",
        "            if \"investor\" in [column.lower() for column in columns]:\n",
        "                query = f'SELECT * FROM {table}'\n",
        "                return query\n",
        "    elif parsed_intent == \"average\":\n",
        "        for table, columns in table_columns.items():\n",
        "            for column in columns:\n",
        "                if \"amount\" in column.lower() or \"value\" in column.lower():\n",
        "                    query = f'SELECT AVG(\"{column}\") FROM {table}'\n",
        "                    return query\n",
        "    elif parsed_intent == \"sum\":\n",
        "        for table, columns in table_columns.items():\n",
        "            for column in columns:\n",
        "                if \"amount\" in column.lower() or \"value\" in column.lower():\n",
        "                    query = f'SELECT SUM(\"{column}\") FROM {table}'\n",
        "                    return query\n",
        "    elif parsed_intent == \"min\":\n",
        "        for table, columns in table_columns.items():\n",
        "            for column in columns:\n",
        "                if \"amount\" in column.lower() or \"value\" in column.lower():\n",
        "                    query = f'SELECT MIN(\"{column}\") FROM {table}'\n",
        "                    return query\n",
        "    elif parsed_intent == \"max\":\n",
        "        for table, columns in table_columns.items():\n",
        "            for column in columns:\n",
        "                if \"amount\" in column.lower() or \"value\" in column.lower():\n",
        "                    query = f'SELECT MAX(\"{column}\") FROM {table}'\n",
        "                    return query\n",
        "    return None\n",
        "\n",
        "\n",
        "def execute_query(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = connection.execute(text(query))\n",
        "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "        return df"
      ],
      "metadata": {
        "id": "bngFL5I5SjOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Explain Results in Natural Language"
      ],
      "metadata": {
        "id": "Um5R3KcHV8H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_results(result_df, parsed_intent, original_question):\n",
        "    if result_df.empty:\n",
        "        return \"No data found.\"\n",
        "\n",
        "    if parsed_intent == \"count\":\n",
        "        count = result_df.iloc[0, 0]\n",
        "        explanation = f\"There are {count} records matching your query.\"\n",
        "    elif parsed_intent == \"retrieve\":\n",
        "        explanation = f\"The query returned {len(result_df)} records. Here are the details:\\n{result_df.to_string(index=False)}\"\n",
        "    elif parsed_intent == \"average\":\n",
        "        avg_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The average value is {avg_value}.\"\n",
        "    elif parsed_intent == \"sum\":\n",
        "        sum_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The total sum is {sum_value}.\"\n",
        "    elif parsed_intent == \"min\":\n",
        "        min_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The minimum value is {min_value}.\"\n",
        "    elif parsed_intent == \"max\":\n",
        "        max_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The maximum value is {max_value}.\"\n",
        "    else:\n",
        "        explanation = \"Query executed successfully.\"\n",
        "\n",
        "    return explanation\n",
        "\n",
        "# Example usage\n",
        "question = \"How many investors are there?\"\n",
        "parsed_intent = parse_user_query(question)\n",
        "query = form_query(parsed_intent, question)\n",
        "if query:\n",
        "    result_df = execute_query(query)\n",
        "    explanation = explain_results(result_df, parsed_intent, question)\n",
        "    print(explanation)"
      ],
      "metadata": {
        "id": "zAMXYxb0SjR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 2"
      ],
      "metadata": {
        "id": "hxy3vnIjnGx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yWfjMBAaoXQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers sqlalchemy psycopg2 pandas\n"
      ],
      "metadata": {
        "id": "giz9eRRgnMm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "62lrsDZ9ojgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "\n",
        "def translate_to_sql_select(english_query):\n",
        "    input_text = f\"translate English to SQL: {english_query}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Function to upload Excel data to PostgreSQL\n",
        "def upload_excel_to_db(file_name, table_name, engine):\n",
        "    # Read the uploaded Excel file into a DataFrame\n",
        "    df = pd.read_excel(file_name)\n",
        "    # Upload the DataFrame to PostgreSQL\n",
        "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
        "    print(f\"Uploaded {file_name} to {table_name} table in PostgreSQL.\")\n"
      ],
      "metadata": {
        "id": "bZY8sxJKowCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File name and table name\n",
        "file_name = '/content/Mock up book.xls'  # Change the path as necessary\n",
        "table_name = 'mock_data'\n",
        "\n",
        "# Upload the Excel data to the database\n",
        "upload_excel_to_db(file_name, table_name, engine)\n"
      ],
      "metadata": {
        "id": "M9oWEAGBpcBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_name"
      ],
      "metadata": {
        "id": "W-0I7kCXt2DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "english_query = \"Show one investor id with firm alloc greater than 5000\"\n",
        "sql_query = translate_to_sql_select(english_query)\n",
        "print(\"SQL Query:\", sql_query)\n",
        "\n",
        "# Load data from the database\n",
        "try:\n",
        "    data = load_data_from_db(sql_query)\n",
        "    print(\"Data from the database:\")\n",
        "    print(data)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "OUZXidClt0x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 3"
      ],
      "metadata": {
        "id": "m5bx_UBjv35r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers torch sqlalchemy pandas psycopg2-binary"
      ],
      "metadata": {
        "id": "kCCs-zx-wfAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, inspect\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)"
      ],
      "metadata": {
        "id": "1BjryHhlv7rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read all tables and columns from the database\n",
        "def get_db_schema(engine):\n",
        "    inspector = inspect(engine)\n",
        "    schema = {}\n",
        "    for table_name in inspector.get_table_names():\n",
        "        columns = inspector.get_columns(table_name)\n",
        "        schema[table_name] = [column['name'] for column in columns]\n",
        "    return schema\n",
        "\n",
        "# Format schema for better input to the model\n",
        "def format_schema(schema):\n",
        "    formatted_schema = []\n",
        "    for table, columns in schema.items():\n",
        "        formatted_columns = \", \".join(columns)\n",
        "        formatted_schema.append(f\"{table}({formatted_columns})\")\n",
        "    return \" | \".join(formatted_schema)"
      ],
      "metadata": {
        "id": "AfnrshXnxIeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the schema\n",
        "schema = get_db_schema(engine)\n",
        "formatted_schema = format_schema(schema)\n",
        "print(formatted_schema)"
      ],
      "metadata": {
        "id": "8Y9LiKktxq7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('cssupport/t5-small-awesome-text-to-sql')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "zPOQeW39xrDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate SQL query from natural language prompt\n",
        "def generate_sql(prompt, formatted_schema):\n",
        "    input_text = f\"{prompt} | {formatted_schema}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True).to(device)\n",
        "    outputs = model.generate(**inputs, max_length=512)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query"
      ],
      "metadata": {
        "id": "EXwhiY6-xrKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"Show one investor id with firm alloc greater than 5000\"\n",
        "sql_query = generate_sql(prompt, formatted_schema)\n",
        "print(f\"Generated SQL query: {sql_query}\")"
      ],
      "metadata": {
        "id": "O-X8VgWmxrM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ],
      "metadata": {
        "id": "L7iYPEUsxrPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the query\n",
        "result_df = load_data_from_db(sql_query)\n",
        "print(result_df)"
      ],
      "metadata": {
        "id": "tiEYiThrxrSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to explain the results\n",
        "def explain_results(result_df):\n",
        "    num_investors = result_df.iloc[0, 0] if not result_df.empty else 0\n",
        "    return f\"There are {num_investors} investors.\""
      ],
      "metadata": {
        "id": "VsGGicgrxrYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain the results\n",
        "explanation = explain_results(result_df)\n",
        "print(explanation)"
      ],
      "metadata": {
        "id": "K_JO483zx5Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 4"
      ],
      "metadata": {
        "id": "vfnbc-ehzSDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers torch sqlalchemy pandas psycopg2-binary"
      ],
      "metadata": {
        "id": "lmntt21gzVFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, inspect\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)"
      ],
      "metadata": {
        "id": "a4sOQvonzWIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read all tables and columns from the database\n",
        "def get_db_schema(engine):\n",
        "    inspector = inspect(engine)\n",
        "    schema = {}\n",
        "    for table_name in inspector.get_table_names():\n",
        "        columns = inspector.get_columns(table_name)\n",
        "        schema[table_name] = [column['name'] for column in columns]\n",
        "    return schema\n",
        "\n",
        "# Format schema for better input to the model\n",
        "def format_schema(schema):\n",
        "    formatted_schema = []\n",
        "    for table, columns in schema.items():\n",
        "        formatted_columns = \", \".join(columns)\n",
        "        formatted_schema.append(f\"{table}({formatted_columns})\")\n",
        "    return \" | \".join(formatted_schema)"
      ],
      "metadata": {
        "id": "y3amQM1JziqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the schema\n",
        "schema = get_db_schema(engine)\n",
        "formatted_schema = format_schema(schema)\n",
        "print(formatted_schema)"
      ],
      "metadata": {
        "id": "yCY9h_Qfzis0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "qzTK61qwziu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate SQL query from natural language prompt\n",
        "def translate_to_sql_select(english_query):\n",
        "    input_text = f\"translate English to SQL: {english_query}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Postprocess SQL query to correct common errors\n",
        "def postprocess_sql(sql_query):\n",
        "    sql_query = sql_query.replace(' , ', ', ')\n",
        "    sql_query = sql_query.replace(' .', '.')\n",
        "    if 'SELECT' not in sql_query.upper():\n",
        "        sql_query = 'SELECT ' + sql_query\n",
        "    return sql_query"
      ],
      "metadata": {
        "id": "lIzU3zH3zi0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"How many investors ids are there\"\n",
        "sql_query = translate_to_sql_select(prompt)\n",
        "sql_query = postprocess_sql(sql_query)\n",
        "print(f\"Generated SQL query: {sql_query}\")"
      ],
      "metadata": {
        "id": "HgsbFtqCzi7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ],
      "metadata": {
        "id": "g3xuKqM4zssx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the query\n",
        "result_df = load_data_from_db(sql_query)\n",
        "print(result_df)"
      ],
      "metadata": {
        "id": "ToM0vCiuzsvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to explain the results\n",
        "def explain_results(result_df):\n",
        "    if result_df.empty:\n",
        "        return \"There are no investors available.\"\n",
        "    num_investors = result_df.iloc[0, 0] if len(result_df.columns) == 1 else len(result_df)\n",
        "    return f\"There are {num_investors} investors.\""
      ],
      "metadata": {
        "id": "Wqr_HpezzsyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain the results\n",
        "explanation = explain_results(result_df)\n",
        "print(explanation)"
      ],
      "metadata": {
        "id": "otbMa7cBzwW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 5"
      ],
      "metadata": {
        "id": "8g0PQIkb3CaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, inspect\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)"
      ],
      "metadata": {
        "id": "_zkU3VQK3Eiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read all tables and columns from the database\n",
        "def get_db_schema(engine):\n",
        "    inspector = inspect(engine)\n",
        "    schema = {}\n",
        "    for table_name in inspector.get_table_names():\n",
        "        columns = inspector.get_columns(table_name)\n",
        "        schema[table_name] = [column['name'] for column in columns]\n",
        "    return schema\n",
        "\n",
        "# Format schema for better input to the model\n",
        "def format_schema(schema):\n",
        "    formatted_schema = []\n",
        "    for table, columns in schema.items():\n",
        "        formatted_columns = \", \".join(columns)\n",
        "        formatted_schema.append(f\"{table}({formatted_columns})\")\n",
        "    return \" | \".join(formatted_schema)"
      ],
      "metadata": {
        "id": "-7ScziSJ4CY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the schema\n",
        "schema = get_db_schema(engine)\n",
        "formatted_schema = format_schema(schema)\n",
        "print(\"Formatted Schema:\", formatted_schema)"
      ],
      "metadata": {
        "id": "Itik8Cwi4G4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "xbu_mjx74G7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate SQL query from natural language prompt\n",
        "def translate_to_sql_select(english_query, formatted_schema):\n",
        "    input_text = f\"Query: {english_query}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Postprocess SQL query to correct common errors\n",
        "def postprocess_sql(sql_query):\n",
        "    sql_query = sql_query.replace(' , ', ', ')\n",
        "    sql_query = sql_query.replace(' .', '.')\n",
        "    if 'SELECT' not in sql_query.upper():\n",
        "        sql_query = 'SELECT ' + sql_query\n",
        "    return sql_query"
      ],
      "metadata": {
        "id": "it84Vv3w4G9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"How many investors are there?\"\n",
        "sql_query = translate_to_sql_select(prompt, formatted_schema)\n",
        "sql_query = postprocess_sql(sql_query)\n",
        "print(f\"Generated SQL query: {sql_query}\")"
      ],
      "metadata": {
        "id": "ZxeYZP_E4G_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ],
      "metadata": {
        "id": "ApYUBAY14HCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the query\n",
        "try:\n",
        "    result_df = load_data_from_db(sql_query)\n",
        "    print(result_df)\n",
        "except Exception as e:\n",
        "    print(f\"Error executing query: {e}\")\n"
      ],
      "metadata": {
        "id": "HTJtnm9k4HEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to explain the results\n",
        "def explain_results(result_df):\n",
        "    if result_df.empty:\n",
        "        return \"There are no investors available.\"\n",
        "    num_investors = result_df.iloc[0, 0] if len(result_df.columns) == 1 else len(result_df)\n",
        "    return f\"There are {num_investors} investors.\""
      ],
      "metadata": {
        "id": "KW0gRQPw4HJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain the results\n",
        "explanation = explain_results(result_df)\n",
        "print(explanation)\n"
      ],
      "metadata": {
        "id": "Uht3UMiy4b5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}