{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69DIWRzxF2Pv"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCZBsbZLeeAW"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_o9igHdF-cM"
      },
      "outputs": [],
      "source": [
        "%pip install pandas openpyxl sqlalchemy psycopg2-binary flair langchain langchain-community langchain-openai fuzzywuzzy python-Levenshtein nltk tqdm openai tabulate lime streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV0zHTEDeT23"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfztWIRCeZSA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import List\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from flair.models import TextClassifier\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import userdata\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UExRrAg6OnA"
      },
      "source": [
        "# Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIwVDDITIXMc"
      },
      "source": [
        "## SQL Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2P80MFRFLiK"
      },
      "outputs": [],
      "source": [
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJL5qPz0JrkG"
      },
      "source": [
        "## Load Excel files in database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQSU5y-VJxSQ"
      },
      "outputs": [],
      "source": [
        "# Read the uploaded Excel file into a DataFrame\n",
        "file_name = '/content/Mock_up_book_to_database.xls'  # uploaded to colab this will be deleted\n",
        "df = pd.read_excel(file_name)\n",
        "\n",
        "# Upload the DataFrame to PostgreSQL\n",
        "table_name = 'mock_data'\n",
        "df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
        "\n",
        "print(f\"Uploaded {file_name} to {table_name} table in PostgreSQL.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOMYbo3hKawX"
      },
      "source": [
        "## Useful functions for querying SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37U0RdSeKuGw"
      },
      "outputs": [],
      "source": [
        "# Lists all tables in database\n",
        "def get_all_tables():\n",
        "    query = \"\"\"\n",
        "    SELECT table_name\n",
        "    FROM information_schema.tables\n",
        "    WHERE table_schema = 'public'\n",
        "    \"\"\"\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Lists the columns in a table and their data type\n",
        "def inspect_columns(table_name):\n",
        "    query = f\"\"\"\n",
        "    SELECT column_name, data_type\n",
        "    FROM information_schema.columns\n",
        "    WHERE table_name = '{table_name}'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with engine.connect() as connection:\n",
        "            result = pd.read_sql_query(query, connection)\n",
        "        print(f\"Columns and their data types in the table {table_name}:\\n\")\n",
        "        print(result)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Returns the first 5 rows\n",
        "def get_top_5_rows(table_name):\n",
        "    query = f\"SELECT * FROM {table_name} LIMIT 5\"\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Executes a given query\n",
        "def execute_query(table_name, query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G8wbIhQHZiW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Example usage\n",
        "inspect_columns('mock_data')\n",
        "\n",
        "table_name = 'mock_data'\n",
        "columns = '\"Feedback\"'\n",
        "query = f\"SELECT {columns} FROM {table_name}\"\n",
        "execute_query(table_name, query)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAkZA2g8VvGr"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12BR3EI6MeHu"
      },
      "outputs": [],
      "source": [
        "table_name = 'mock_data'\n",
        "columns = '*'\n",
        "query = f\"SELECT {columns} FROM {table_name}\"\n",
        "df = execute_query(table_name, query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOfKxSXBY9Ja"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrN_4k7SQvo1"
      },
      "source": [
        "# Open Source Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNfVsbfNPMTG"
      },
      "source": [
        "## Flair Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUWhiYZgQaQJ"
      },
      "outputs": [],
      "source": [
        "# Import flair Sentence to process input text\n",
        "from flair.data import Sentence\n",
        "# Import accuracy_score to check performance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "flair_classifier = TextClassifier.load('en-sentiment')\n",
        "\n",
        "def flair_sentiment(text):\n",
        "    sentence = Sentence(text)\n",
        "    flair_classifier.predict(sentence)\n",
        "    score = sentence.labels[0].score\n",
        "    label = sentence.labels[0].value\n",
        "    return label, score\n",
        "\n",
        "df['flair_sentiment'], df['flair_score'] = zip(*df['Feedback'].apply(flair_sentiment))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_cgFD8QQ8Up"
      },
      "source": [
        "## Finbert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgXa_SpFxx7g"
      },
      "outputs": [],
      "source": [
        "# Load the FinBERT tokenizer and model\n",
        "finbert_tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "finbert_model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
        "\n",
        "# Create a sentiment analysis pipeline for FinBERT\n",
        "finbert_sentiment_analysis = pipeline('sentiment-analysis', model=finbert_model, tokenizer=finbert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf72YrOTVylW"
      },
      "outputs": [],
      "source": [
        "# Perform sentiment analysis using FinBERT\n",
        "df['finbert_sentiment'] = df['Feedback'].apply(lambda x: finbert_sentiment_analysis(x)[0]['label'])\n",
        "df['finbert_score'] = df['Feedback'].apply(lambda x: finbert_sentiment_analysis(x)[0]['score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUUJyMSkfSUD"
      },
      "source": [
        "## Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vLfAOXGfW5B"
      },
      "outputs": [],
      "source": [
        "# Load the standard BERT tokenizer and model for sentiment analysis\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q70XVM4fenc"
      },
      "outputs": [],
      "source": [
        "# Create a sentiment analysis pipeline for BERT\n",
        "bert_sentiment_analysis = pipeline('sentiment-analysis', model=bert_model, tokenizer=bert_tokenizer)\n",
        "\n",
        "# Perform sentiment analysis using standard BERT and map star ratings to sentiment labels\n",
        "def map_bert_sentiment(bert_output):\n",
        "    star_label = bert_output[0]['label']\n",
        "    score = bert_output[0]['score']\n",
        "    if star_label in ['1 star', '2 stars']:\n",
        "        sentiment = 'negative'\n",
        "    elif star_label == '3 stars':\n",
        "        sentiment = 'neutral'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "    return sentiment, score\n",
        "\n",
        "df['bert_sentiment'], df['bert_score'] = zip(*df['Feedback'].apply(lambda x: map_bert_sentiment(bert_sentiment_analysis(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG2_gSKCR7nc"
      },
      "source": [
        "# Closed Source Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iclMY3Lq6ds1"
      },
      "source": [
        "## OpenAI gpt-3.5-turbo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W1zMAdF6mBw"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Fetch the API key from Google Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize OpenAI client with the API key\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "def openai_sentiment(text):\n",
        "    prompt = f\"Please provide only the sentiment (Positive, Neutral, Negative), and provide only the numerical score (the model score) in the following format (example): neutral---0.88. The delimeter '---' between sentiment and score should be included all the time. Do not include anything else. Do it for the following text:\\n\\n{text}\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        sentiment = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Split the sentiment into two variables\n",
        "        sentiment_parts = sentiment.split('---')\n",
        "        if len(sentiment_parts) == 2:\n",
        "            openai_sentiment = sentiment_parts[0]\n",
        "            openai_score = sentiment_parts[1]\n",
        "        else:\n",
        "            print(sentiment)\n",
        "            raise ValueError(\"Unexpected response format\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle any exception and return default values\n",
        "        print(f\"Error processing text: {text}. Error: {e}\")\n",
        "        openai_sentiment, openai_score = 'error', '0.0'\n",
        "\n",
        "    return openai_sentiment, openai_score\n",
        "\n",
        "# Convert 'Feedback' to string and perform sentiment analysis using OpenAI API\n",
        "df['openai_sentiment_3.5'], df['openai_score_3.5'] = zip(*df['Feedback'].apply(lambda x: openai_sentiment(str(x))))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7LYamEnRSt_"
      },
      "source": [
        "## OpenAI gpt-4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRzoLidxRUpv"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Fetch the API key from Google Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize OpenAI client with the API key\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "def openai_sentiment(text):\n",
        "    prompt = f\"Please provide only the sentiment (Positive, Negative), and provide only the numerical score (the model score) in the following format: sentiment---numerical score. This is a delimeter and should be included all the time. Do not include anything else. Do it for the following text:\\n\\n{text}.\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert in capital markets.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        sentiment = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Split the sentiment into two variables\n",
        "        sentiment_parts = sentiment.split('---')\n",
        "        if len(sentiment_parts) == 2:\n",
        "            openai_sentiment = sentiment_parts[0]\n",
        "            openai_score = sentiment_parts[1]\n",
        "        else:\n",
        "            print(sentiment)\n",
        "            raise ValueError(\"Unexpected response format\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle any exception and return default values\n",
        "        print(f\"Error processing text: {text}. Error: {e}\")\n",
        "        openai_sentiment, openai_score = 'error', '0.0'\n",
        "\n",
        "    return openai_sentiment, openai_score\n",
        "\n",
        "# Convert 'Feedback' to string and perform sentiment analysis using OpenAI API\n",
        "df['openai_sentiment_4.0'], df['openai_score_4.0'] = zip(*df['Feedback'].apply(lambda x: openai_sentiment(str(x))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZYrxM59STCa"
      },
      "source": [
        "# Sentiment Analysis Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCz6mhK2beqC"
      },
      "source": [
        "##Combine all models into one DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5Z5lxaJgO34"
      },
      "outputs": [],
      "source": [
        "# Convert all string columns to lowercase\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':  # Check if the column's dtype is object (usually indicates strings)\n",
        "        df[col] = df[col].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0O6vJmZbdAl"
      },
      "outputs": [],
      "source": [
        "# Create a combined DataFrame for sentiment analysis (all models)\n",
        "combined_df = df[['Feedback','GP Sentiment', 'finbert_sentiment', 'finbert_score', 'flair_sentiment', 'flair_score', 'bert_sentiment', 'bert_score', 'openai_sentiment_3.5', 'openai_score_3.5','openai_sentiment_4.0', 'openai_score_4.0']]\n",
        "\n",
        "# Save the combined results to a new CSV file\n",
        "combined_output_csv = 'sentiment_analysis_all_models.csv'  # Replace with the desired output file path\n",
        "combined_df.to_csv(combined_output_csv, index=False)\n",
        "\n",
        "# Display the combined results\n",
        "print(combined_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKQqwq3_hWra"
      },
      "source": [
        "##Models comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMfmKQ_1hgQ_"
      },
      "source": [
        "### Calculate Agreement Rates\n",
        "(Determine how often the models agree on the sentiment (positive, neutral, negative))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvCLSSGxh4vj"
      },
      "outputs": [],
      "source": [
        "# Calculate agreement rates\n",
        "agreement_df = combined_df[['finbert_sentiment', 'flair_sentiment', 'bert_sentiment', 'openai_sentiment_3.5', 'openai_sentiment_4.0']].copy()\n",
        "\n",
        "# Function to check agreement\n",
        "def check_agreement(row):\n",
        "    return row.nunique() == 1\n",
        "\n",
        "agreement_df['agreement'] = agreement_df.apply(check_agreement, axis=1)\n",
        "\n",
        "# Calculate the percentage of agreement\n",
        "agreement_rate = agreement_df['agreement'].mean()\n",
        "print(f\"Agreement rate among all four models: {agreement_rate:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWZlQ76ib-g"
      },
      "source": [
        "### Visualize Sentiment Distribution\n",
        "(Plot the distribution of sentiments assigned by each model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNZcoGEGilU_"
      },
      "outputs": [],
      "source": [
        "# Visualize sentiment distribution\n",
        "sentiment_counts = combined_df[['finbert_sentiment', 'flair_sentiment', 'bert_sentiment', 'openai_sentiment_3.5', 'openai_sentiment_4.0']].apply(pd.Series.value_counts).fillna(0)\n",
        "sentiment_counts.plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Sentiment Distribution Across Models')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Model')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9JQBPPbitKE"
      },
      "source": [
        "### Compare Average Scores\n",
        "(Calculate and compare the average sentiment scores for each model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8j2wQ67iwZh"
      },
      "outputs": [],
      "source": [
        "def convert_to_numeric(df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "score_columns = ['finbert_score', 'flair_score', 'bert_score', 'openai_score_3.5', 'openai_score_4.0']\n",
        "combined_df = convert_to_numeric(combined_df, score_columns)\n",
        "\n",
        "# Compare average scores\n",
        "average_scores = combined_df[score_columns].mean()\n",
        "print(\"Average Scores:\")\n",
        "print(average_scores)\n",
        "\n",
        "# Visualize average scores\n",
        "average_scores.plot(kind='bar', figsize=(8, 5))\n",
        "plt.title('Average Sentiment Scores Across Models')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Average Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXHmXfnaTE84"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = combined_df[score_columns].corr()\n",
        "\n",
        "# Create a heatmap for the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap of Sentiment Scores Across Models')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSA_8TdaUPUF"
      },
      "outputs": [],
      "source": [
        "# This visualization will show the pairwise relationships between the sentiment scores of different models:\n",
        "sns.pairplot(combined_df[score_columns])\n",
        "plt.suptitle('Pair Plot of Sentiment Scores Across Models', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnEokHnTVRIo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=combined_df[score_columns])\n",
        "plt.title('Box Plot of Sentiment Scores Across Models')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCNb6ot-b-bo"
      },
      "outputs": [],
      "source": [
        "# Define a function to map sentiment labels to standardized names\n",
        "def standardize_sentiment(sentiment):\n",
        "    if sentiment.lower() in ['positive', 'pos']:\n",
        "        return 'Positive'\n",
        "    elif sentiment.lower() in ['negative', 'neg']:\n",
        "        return 'Negative'\n",
        "    elif sentiment.lower() in ['neutral', 'neut']:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return sentiment  # Return the original value if it doesn't match any standard label\n",
        "\n",
        "# Apply the function to all relevant columns\n",
        "sentiment_columns = ['GP Sentiment', 'finbert_sentiment', 'flair_sentiment', 'bert_sentiment',\n",
        "                     'openai_sentiment_3.5', 'openai_sentiment_4.0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqrVWRECcGE4"
      },
      "outputs": [],
      "source": [
        "for col in sentiment_columns:\n",
        "    combined_df[col] = combined_df[col].apply(standardize_sentiment)\n",
        "\n",
        "# Example: Checking unique values after standardization\n",
        "for col in sentiment_columns:\n",
        "    unique_values = combined_df[col].unique()\n",
        "    print(f\"Unique values in {col}: {unique_values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FInQIqmabaDj"
      },
      "outputs": [],
      "source": [
        "# Count matches between GP Sentiment and each model's predictions\n",
        "matches_finbert = (combined_df['GP Sentiment'] == combined_df['finbert_sentiment']).sum()\n",
        "matches_flair = (combined_df['GP Sentiment'] == combined_df['flair_sentiment']).sum()\n",
        "matches_bert = (combined_df['GP Sentiment'] == combined_df['bert_sentiment']).sum()\n",
        "matches_openai_3_5 = (combined_df['GP Sentiment'] == combined_df['openai_sentiment_3.5']).sum()\n",
        "matches_openai_4_0 = (combined_df['GP Sentiment'] == combined_df['openai_sentiment_4.0']).sum()\n",
        "\n",
        "print(f\"Matches with GP Sentiment (FinBERT): {matches_finbert}\")\n",
        "print(f\"Matches with GP Sentiment (Flair): {matches_flair}\")\n",
        "print(f\"Matches with GP Sentiment (BERT): {matches_bert}\")\n",
        "print(f\"Matches with GP Sentiment (OpenAI 3.5): {matches_openai_3_5}\")\n",
        "print(f\"Matches with GP Sentiment (OpenAI 4.0): {matches_openai_4_0}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VeTprAFc0XS"
      },
      "outputs": [],
      "source": [
        "total_samples = len(combined_df)\n",
        "match_percentages = {}\n",
        "\n",
        "# Calculate percentage of matches for each sentiment column\n",
        "for col in sentiment_columns:\n",
        "    matches = (combined_df['GP Sentiment'] == combined_df[col]).sum()\n",
        "    percentage_match = (matches / total_samples) * 100\n",
        "    match_percentages[col] = percentage_match\n",
        "\n",
        "# Print results\n",
        "for col, percentage in match_percentages.items():\n",
        "    print(f\"Percentage of matches with GP Sentiment ({col}): {percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZunNwcsdmuq"
      },
      "outputs": [],
      "source": [
        "sentiment_columns_wo_GP = ['finbert_sentiment', 'flair_sentiment', 'bert_sentiment',\n",
        "                     'openai_sentiment_3.5', 'openai_sentiment_4.0']\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Calculate metrics for each sentiment column excluding GP Sentiment\n",
        "for col in sentiment_columns_wo_GP:\n",
        "        accuracy = accuracy_score(combined_df['GP Sentiment'], combined_df[col])\n",
        "\n",
        "        # Calculate precision, recall, and F1-score\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(combined_df['GP Sentiment'], combined_df[col], average='weighted')\n",
        "\n",
        "        # Append scores to lists\n",
        "        accuracy_scores.append(accuracy)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        # Print results for each sentiment column\n",
        "        print(f\"Metrics for {col}:\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "# Average scores across all sentiment columns\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "average_precision = sum(precision_scores) / len(precision_scores)\n",
        "average_recall = sum(recall_scores) / len(recall_scores)\n",
        "average_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "print(\"Average Metrics Across Sentiment Columns:\")\n",
        "print(f\"Average Accuracy: {average_accuracy:.2f}\")\n",
        "print(f\"Average Precision: {average_precision:.2f}\")\n",
        "print(f\"Average Recall: {average_recall:.2f}\")\n",
        "print(f\"Average F1-score: {average_f1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIWHyV8Zbcww"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilqf7xze_N1k"
      },
      "source": [
        "## LIME (Local Interpretable Model-agnostic Explanations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYgFXqrZ_qHO"
      },
      "outputs": [],
      "source": [
        "# Initialize LIME explainer\n",
        "explainer = LimeTextExplainer(class_names=['positive', 'neutral', 'negative'])\n",
        "\n",
        "# Explain the prediction for a single example from each model\n",
        "def explain_prediction(text, model_name):\n",
        "    if model_name == 'finbert':\n",
        "        exp = explainer.explain_instance(text, lambda x: [finbert_sentiment_analysis(x)], num_features=10)\n",
        "    elif model_name == 'flair':\n",
        "        exp = explainer.explain_instance(text, lambda x: [flair_sentiment(x)], num_features=10)\n",
        "    elif model_name == 'bert':\n",
        "        exp = explainer.explain_instance(text, lambda x: [bert_sentiment_analysis(x)], num_features=10)\n",
        "    elif model_name == 'openai':\n",
        "        exp = explainer.explain_instance(text, lambda x: [openai_sentiment(x)], num_features=10)\n",
        "    return exp\n",
        "\n",
        "# Test explanation for the first feedback example\n",
        "example_text = df['Feedback'].iloc[0]\n",
        "finbert_exp = explain_prediction(example_text, 'finbert')\n",
        "flair_exp = explain_prediction(example_text, 'flair')\n",
        "bert_exp = explain_prediction(example_text, 'bert')\n",
        "openai_exp = explain_prediction(example_text, 'openai')\n",
        "\n",
        "# Visualize explanations\n",
        "finbert_exp.show_in_notebook(text=example_text)\n",
        "flair_exp.show_in_notebook(text=example_text)\n",
        "bert_exp.show_in_notebook(text=example_text)\n",
        "openai_exp.show_in_notebook(text=example_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un9EV4FplLmb"
      },
      "source": [
        "# Open-Source Text2SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12tfFIDnoZak"
      },
      "source": [
        "## Approach 1 (Working)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bEok3_6Vnuw"
      },
      "source": [
        "Step 1: Connect to the Database and Obtain Table and Column Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy5TlqqhodnS"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, MetaData\n",
        "\n",
        "# Database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create an engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Connect to the database and fetch table and column names\n",
        "metadata = MetaData()\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Store table and column names\n",
        "table_columns = {}\n",
        "for table in metadata.tables.values():\n",
        "    table_columns[table.name] = [column.name for column in table.c]\n",
        "\n",
        "# Print table and column names\n",
        "for table, columns in table_columns.items():\n",
        "    print(f\"Table: {table}\\nColumns: {columns}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qon6z3JKVp5I"
      },
      "source": [
        "Step 2: Use NLP to Parse the User Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNKkWfMvSjMP"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from fuzzywuzzy import process\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load Spacy model\n",
        "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load a pre-trained model for zero-shot classification\n",
        "nlp_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Example categories for intent classification\n",
        "categories = [\"count\", \"retrieve\", \"average\", \"sum\", \"min\", \"max\", \"unique count\"]\n",
        "\n",
        "# Filter-indicating words\n",
        "filter_keywords = {'that', 'where', 'which', 'over', 'under', 'greater', 'less', 'have', 'has'}\n",
        "\n",
        "def parse_user_query():\n",
        "    question = input(\"Please enter your question: \")\n",
        "    intent_result = nlp_model(question, candidate_labels=categories)\n",
        "    intent = intent_result['labels'][0]  # Most likely intent\n",
        "    return intent, question\n",
        "\n",
        "def extract_pre_filter_keywords(question):\n",
        "    # Split question at the filter keywords\n",
        "    tokens = question.lower().split()\n",
        "    split_index = len(tokens)\n",
        "    for i, token in enumerate(tokens):\n",
        "        if token in filter_keywords:\n",
        "            split_index = i\n",
        "            break\n",
        "\n",
        "    pre_filter_tokens = tokens[:split_index]\n",
        "    keywords = [word for word in pre_filter_tokens if word.isalpha()]\n",
        "\n",
        "    return keywords\n",
        "\n",
        "def match_columns(keywords, priority_terms=[]):\n",
        "    matched_columns = []\n",
        "    for table, col_list in table_columns.items():\n",
        "        for keyword in tqdm(keywords, desc=\"Matching columns\"):\n",
        "            closest_match = process.extract(keyword, col_list, limit=3)\n",
        "            for match in closest_match:\n",
        "                matched_columns.append((table, match[0], match[1]))\n",
        "\n",
        "    # Increase confidence for priority terms\n",
        "    for i, (table, column, confidence) in enumerate(matched_columns):\n",
        "        for term in priority_terms:\n",
        "            if term in column.lower():\n",
        "                matched_columns[i] = (table, column, confidence + 20)\n",
        "\n",
        "    matched_columns = sorted(matched_columns, key=lambda x: x[2], reverse=True)  # Sort by confidence, descending\n",
        "    return matched_columns\n",
        "\n",
        "def needs_filter(question):\n",
        "    tokens = question.lower().split()\n",
        "    return any(token in filter_keywords for token in tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV-F6GdbV4GD"
      },
      "source": [
        "Step 3: Dynamically Form and Execute SQL Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bngFL5I5SjOp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy.sql import text\n",
        "\n",
        "def extract_filter_conditions(filter_input):\n",
        "    doc = nlp_spacy(filter_input)\n",
        "    conditions = []\n",
        "\n",
        "    operators = {\n",
        "        'greater': '>',\n",
        "        'more': '>',\n",
        "        'less': '<',\n",
        "        'fewer': '<',\n",
        "        'equal': '=',\n",
        "        'over': '>',\n",
        "        'under': '<',\n",
        "        'above': '>',\n",
        "        'below': '<'\n",
        "    }\n",
        "\n",
        "    current_column = None\n",
        "    operator = None\n",
        "    value = None\n",
        "\n",
        "    for token in doc:\n",
        "        if token.text.lower() in operators:\n",
        "            operator = operators[token.text.lower()]\n",
        "        elif token.like_num:\n",
        "            value = token.text\n",
        "        elif token.text.isalpha():\n",
        "            current_column = token.text\n",
        "\n",
        "    if current_column and operator and value:\n",
        "        conditions.append((current_column, operator, value))\n",
        "\n",
        "    return conditions\n",
        "\n",
        "def form_query(parsed_intent, question):\n",
        "    pre_filter_keywords = extract_pre_filter_keywords(question)\n",
        "    matched_columns = match_columns(pre_filter_keywords, priority_terms=[\"investor\", \"firm\"])\n",
        "\n",
        "    if not matched_columns:\n",
        "        print(\"No columns matched.\")\n",
        "        return None\n",
        "\n",
        "    select_columns = []\n",
        "    for table, column, confidence in matched_columns:\n",
        "        if confidence >= 95:\n",
        "            select_columns.append((table, column))\n",
        "        else:\n",
        "            break  # Only show suggestions if confidence is below 95%\n",
        "\n",
        "    if not select_columns and matched_columns:\n",
        "        print(f\"\\nThe script is not fully confident about the columns. Here are the suggestions:\\n\")\n",
        "        for i, (table, column, confidence) in enumerate(matched_columns):\n",
        "            print(f\"{i+1}. Table: {table}, Column: {column}, Confidence: {confidence}%\\n\")\n",
        "\n",
        "        choice = input(\"Choose the number of the correct column or press enter to use the highest confidence match: \")\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(matched_columns):\n",
        "            index = int(choice) - 1\n",
        "            select_columns.append((matched_columns[index][0], matched_columns[index][1]))\n",
        "        else:\n",
        "            select_columns.append((matched_columns[0][0], matched_columns[0][1]))  # Use highest confidence match\n",
        "\n",
        "    if not select_columns:\n",
        "        print(\"No columns confirmed.\")\n",
        "        return None\n",
        "\n",
        "    where_clause = ''\n",
        "    if needs_filter(question):\n",
        "        filter_input = input(\"As I understand, you want to filter some of your results. Explain to me in your words the filter that should be applied. If you do not want an extra filter, type 'Continue': \")\n",
        "        if filter_input.lower() != 'continue':\n",
        "            filter_conditions = extract_filter_conditions(filter_input)\n",
        "            for col_keyword, operator, value in filter_conditions:\n",
        "                matched_filter_columns = match_columns([col_keyword])\n",
        "                if matched_filter_columns:\n",
        "                    best_match = matched_filter_columns[0]\n",
        "                    if best_match[2] < 90:\n",
        "                        table, col_list = best_match[0], table_columns[best_match[0]]\n",
        "                        print(f\"\\nThe script is not fully confident about the column that should be filtered. Here are the columns in the table '{table}':\\n\")\n",
        "                        for i, col in enumerate(col_list, 1):\n",
        "                            print(f\"{i+1}. {col}\\n\")\n",
        "                        col_choice = input(\"Choose the number of the correct column: \")\n",
        "                        if col_choice.isdigit() and 1 <= int(col_choice) <= len(col_list):\n",
        "                            chosen_column = col_list[int(col_choice) - 1]\n",
        "                            where_clause += f' AND \"{chosen_column}\" {operator} {value}'\n",
        "                    else:\n",
        "                        where_clause += f' AND \"{best_match[1]}\" {operator} {value}'\n",
        "            if where_clause:\n",
        "                where_clause = where_clause.lstrip(' AND')\n",
        "\n",
        "    query = None\n",
        "    if parsed_intent == \"count\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT COUNT(\"{column}\") FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    elif parsed_intent == \"retrieve\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT * FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    elif parsed_intent == \"average\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT AVG(\"{column}\") FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    elif parsed_intent == \"sum\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT SUM(\"{column}\") FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    elif parsed_intent == \"min\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT MIN(\"{column}\") FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    elif parsed_intent == \"max\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT MAX(\"{column}\") FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    elif parsed_intent == \"unique count\":\n",
        "        for table, column in select_columns:\n",
        "            query = f'SELECT COUNT(DISTINCT \"{column}\") FROM {table}'\n",
        "            if where_clause:\n",
        "                query += f' WHERE {where_clause}'\n",
        "            return query\n",
        "    return None\n",
        "\n",
        "def execute_query(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = connection.execute(text(query))\n",
        "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um5R3KcHV8H-"
      },
      "source": [
        "Step 4: Explain Results in Natural Language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAMXYxb0SjR_"
      },
      "outputs": [],
      "source": [
        "def explain_results(result_df, parsed_intent, original_question):\n",
        "    if result_df.empty:\n",
        "        return \"No data found.\"\n",
        "\n",
        "    if parsed_intent == \"count\":\n",
        "        count = result_df.iloc[0, 0]\n",
        "        explanation = f\"There are {count} records matching your query.\"\n",
        "    elif parsed_intent == \"retrieve\":\n",
        "        explanation = f\"The query returned {len(result_df)} records. Here are the details:\"\n",
        "    elif parsed_intent == \"average\":\n",
        "        avg_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The average value is {avg_value}.\"\n",
        "    elif parsed_intent == \"sum\":\n",
        "        sum_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The total sum is {sum_value}.\"\n",
        "    elif parsed_intent == \"min\":\n",
        "        min_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The minimum value is {min_value}.\"\n",
        "    elif parsed_intent == \"max\":\n",
        "        max_value = result_df.iloc[0, 0]\n",
        "        explanation = f\"The maximum value is {max_value}.\"\n",
        "    elif parsed_intent == \"unique count\":\n",
        "        unique_count = result_df.iloc[0, 0]\n",
        "        explanation = f\"There are {unique_count} unique records matching your query.\"\n",
        "    else:\n",
        "        explanation = \"Query executed successfully.\"\n",
        "\n",
        "    return explanation, result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roR6E1K-ZIGX"
      },
      "outputs": [],
      "source": [
        "# Main script\n",
        "parsed_intent, question = parse_user_query()\n",
        "query = form_query(parsed_intent, question)\n",
        "if query:\n",
        "    result_df = execute_query(query)\n",
        "    explanation, result_df = explain_results(result_df, parsed_intent, question)\n",
        "    output_message = f\"The intent of the question was: {parsed_intent}\\n\\nThe question was: {question}\\n\\n{explanation}\"\n",
        "    print(query, output_message)\n",
        "    display(result_df)  # Use Jupyter's display function to show the DataFrame\n",
        "else:\n",
        "    print(\"Could not generate a query based on the input.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kuPnXBI1qZ-"
      },
      "source": [
        "## Other Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxy3vnIjnGx8"
      },
      "source": [
        "### Approach 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfjMBAaoXQO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "giz9eRRgnMm1"
      },
      "outputs": [],
      "source": [
        "%pip install transformers sqlalchemy psycopg2 pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "62lrsDZ9ojgz"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZY8sxJKowCR"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "\n",
        "def translate_to_sql_select(english_query):\n",
        "    input_text = f\"translate English to SQL: {english_query}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Function to upload Excel data to PostgreSQL\n",
        "def upload_excel_to_db(file_name, table_name, engine):\n",
        "    # Read the uploaded Excel file into a DataFrame\n",
        "    df = pd.read_excel(file_name)\n",
        "    # Upload the DataFrame to PostgreSQL\n",
        "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
        "    print(f\"Uploaded {file_name} to {table_name} table in PostgreSQL.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9oWEAGBpcBT"
      },
      "outputs": [],
      "source": [
        "# File name and table name\n",
        "file_name = '/content/Mock up book.xls'  # Change the path as necessary\n",
        "table_name = 'mock_data'\n",
        "\n",
        "# Upload the Excel data to the database\n",
        "upload_excel_to_db(file_name, table_name, engine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-0I7kCXt2DV"
      },
      "outputs": [],
      "source": [
        "table_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUZXidClt0x1"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "english_query = \"Show one investor id with firm alloc greater than 5000\"\n",
        "sql_query = translate_to_sql_select(english_query)\n",
        "print(\"SQL Query:\", sql_query)\n",
        "\n",
        "# Load data from the database\n",
        "try:\n",
        "    data = load_data_from_db(sql_query)\n",
        "    print(\"Data from the database:\")\n",
        "    print(data)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5bx_UBjv35r"
      },
      "source": [
        "### Approach 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCCs-zx-wfAL"
      },
      "outputs": [],
      "source": [
        "%pip install transformers torch sqlalchemy pandas psycopg2-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BjryHhlv7rc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, inspect\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfnrshXnxIeJ"
      },
      "outputs": [],
      "source": [
        "# Function to read all tables and columns from the database\n",
        "def get_db_schema(engine):\n",
        "    inspector = inspect(engine)\n",
        "    schema = {}\n",
        "    for table_name in inspector.get_table_names():\n",
        "        columns = inspector.get_columns(table_name)\n",
        "        schema[table_name] = [column['name'] for column in columns]\n",
        "    return schema\n",
        "\n",
        "# Format schema for better input to the model\n",
        "def format_schema(schema):\n",
        "    formatted_schema = []\n",
        "    for table, columns in schema.items():\n",
        "        formatted_columns = \", \".join(columns)\n",
        "        formatted_schema.append(f\"{table}({formatted_columns})\")\n",
        "    return \" | \".join(formatted_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y9LiKktxq7T"
      },
      "outputs": [],
      "source": [
        "# Load the schema\n",
        "schema = get_db_schema(engine)\n",
        "formatted_schema = format_schema(schema)\n",
        "print(formatted_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPOQeW39xrDK"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('cssupport/t5-small-awesome-text-to-sql')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXwhiY6-xrKE"
      },
      "outputs": [],
      "source": [
        "# Function to generate SQL query from natural language prompt\n",
        "def generate_sql(prompt, formatted_schema):\n",
        "    input_text = f\"{prompt} | {formatted_schema}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True).to(device)\n",
        "    outputs = model.generate(**inputs, max_length=512)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-X8VgWmxrM4"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "prompt = \"Show one investor id with firm alloc greater than 5000\"\n",
        "sql_query = generate_sql(prompt, formatted_schema)\n",
        "print(f\"Generated SQL query: {sql_query}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7iYPEUsxrPy"
      },
      "outputs": [],
      "source": [
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiEYiThrxrSL"
      },
      "outputs": [],
      "source": [
        "# Execute the query\n",
        "result_df = load_data_from_db(sql_query)\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsGGicgrxrYl"
      },
      "outputs": [],
      "source": [
        "# Function to explain the results\n",
        "def explain_results(result_df):\n",
        "    num_investors = result_df.iloc[0, 0] if not result_df.empty else 0\n",
        "    return f\"There are {num_investors} investors.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_JO483zx5Om"
      },
      "outputs": [],
      "source": [
        "# Explain the results\n",
        "explanation = explain_results(result_df)\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfnbc-ehzSDw"
      },
      "source": [
        "### Approach 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmntt21gzVFT"
      },
      "outputs": [],
      "source": [
        "%pip install transformers torch sqlalchemy pandas psycopg2-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4sOQvonzWIS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, inspect\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3amQM1JziqB"
      },
      "outputs": [],
      "source": [
        "# Function to read all tables and columns from the database\n",
        "def get_db_schema(engine):\n",
        "    inspector = inspect(engine)\n",
        "    schema = {}\n",
        "    for table_name in inspector.get_table_names():\n",
        "        columns = inspector.get_columns(table_name)\n",
        "        schema[table_name] = [column['name'] for column in columns]\n",
        "    return schema\n",
        "\n",
        "# Format schema for better input to the model\n",
        "def format_schema(schema):\n",
        "    formatted_schema = []\n",
        "    for table, columns in schema.items():\n",
        "        formatted_columns = \", \".join(columns)\n",
        "        formatted_schema.append(f\"{table}({formatted_columns})\")\n",
        "    return \" | \".join(formatted_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCY9h_Qfzis0"
      },
      "outputs": [],
      "source": [
        "# Load the schema\n",
        "schema = get_db_schema(engine)\n",
        "formatted_schema = format_schema(schema)\n",
        "print(formatted_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzTK61qwziu7"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIzU3zH3zi0y"
      },
      "outputs": [],
      "source": [
        "# Function to generate SQL query from natural language prompt\n",
        "def translate_to_sql_select(english_query):\n",
        "    input_text = f\"translate English to SQL: {english_query}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Postprocess SQL query to correct common errors\n",
        "def postprocess_sql(sql_query):\n",
        "    sql_query = sql_query.replace(' , ', ', ')\n",
        "    sql_query = sql_query.replace(' .', '.')\n",
        "    if 'SELECT' not in sql_query.upper():\n",
        "        sql_query = 'SELECT ' + sql_query\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgsbFtqCzi7o"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "prompt = \"How many investors ids are there\"\n",
        "sql_query = translate_to_sql_select(prompt)\n",
        "sql_query = postprocess_sql(sql_query)\n",
        "print(f\"Generated SQL query: {sql_query}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3xuKqM4zssx"
      },
      "outputs": [],
      "source": [
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToM0vCiuzsvY"
      },
      "outputs": [],
      "source": [
        "# Execute the query\n",
        "result_df = load_data_from_db(sql_query)\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqr_HpezzsyC"
      },
      "outputs": [],
      "source": [
        "# Function to explain the results\n",
        "def explain_results(result_df):\n",
        "    if result_df.empty:\n",
        "        return \"There are no investors available.\"\n",
        "    num_investors = result_df.iloc[0, 0] if len(result_df.columns) == 1 else len(result_df)\n",
        "    return f\"There are {num_investors} investors.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otbMa7cBzwW5"
      },
      "outputs": [],
      "source": [
        "# Explain the results\n",
        "explanation = explain_results(result_df)\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g0PQIkb3CaT"
      },
      "source": [
        "### Approach 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zkU3VQK3Eiw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, inspect\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7ScziSJ4CY9"
      },
      "outputs": [],
      "source": [
        "# Function to read all tables and columns from the database\n",
        "def get_db_schema(engine):\n",
        "    inspector = inspect(engine)\n",
        "    schema = {}\n",
        "    for table_name in inspector.get_table_names():\n",
        "        columns = inspector.get_columns(table_name)\n",
        "        schema[table_name] = [column['name'] for column in columns]\n",
        "    return schema\n",
        "\n",
        "# Format schema for better input to the model\n",
        "def format_schema(schema):\n",
        "    formatted_schema = []\n",
        "    for table, columns in schema.items():\n",
        "        formatted_columns = \", \".join(columns)\n",
        "        formatted_schema.append(f\"{table}({formatted_columns})\")\n",
        "    return \" | \".join(formatted_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Itik8Cwi4G4x"
      },
      "outputs": [],
      "source": [
        "# Load the schema\n",
        "schema = get_db_schema(engine)\n",
        "formatted_schema = format_schema(schema)\n",
        "print(\"Formatted Schema:\", formatted_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbu_mjx74G7a"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"suriya7/t5-base-text-to-sql\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it84Vv3w4G9r"
      },
      "outputs": [],
      "source": [
        "# Function to generate SQL query from natural language prompt\n",
        "def translate_to_sql_select(english_query, formatted_schema):\n",
        "    input_text = f\"Query: {english_query}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=100)\n",
        "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return sql_query\n",
        "\n",
        "# Postprocess SQL query to correct common errors\n",
        "def postprocess_sql(sql_query):\n",
        "    sql_query = sql_query.replace(' , ', ', ')\n",
        "    sql_query = sql_query.replace(' .', '.')\n",
        "    if 'SELECT' not in sql_query.upper():\n",
        "        sql_query = 'SELECT ' + sql_query\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxeYZP_E4G_3"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "prompt = \"How many investors are there?\"\n",
        "sql_query = translate_to_sql_select(prompt, formatted_schema)\n",
        "sql_query = postprocess_sql(sql_query)\n",
        "print(f\"Generated SQL query: {sql_query}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApYUBAY14HCa"
      },
      "outputs": [],
      "source": [
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTJtnm9k4HEv"
      },
      "outputs": [],
      "source": [
        "# Execute the query\n",
        "try:\n",
        "    result_df = load_data_from_db(sql_query)\n",
        "    print(result_df)\n",
        "except Exception as e:\n",
        "    print(f\"Error executing query: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW0gRQPw4HJT"
      },
      "outputs": [],
      "source": [
        "# Function to explain the results\n",
        "def explain_results(result_df):\n",
        "    if result_df.empty:\n",
        "        return \"There are no investors available.\"\n",
        "    num_investors = result_df.iloc[0, 0] if len(result_df.columns) == 1 else len(result_df)\n",
        "    return f\"There are {num_investors} investors.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uht3UMiy4b5j"
      },
      "outputs": [],
      "source": [
        "# Explain the results\n",
        "explanation = explain_results(result_df)\n",
        "print(explanation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEZOhEzbIA_I"
      },
      "source": [
        "# Closed-Source Text2SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USeTR2KXEMKB"
      },
      "source": [
        "## Text2SQL OpenAI gpt-3.5-turbo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK2djDjibk6N"
      },
      "source": [
        "Step 1: Database Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT5WJGr_IEF2"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, inspect\n",
        "\n",
        "# Database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create an engine\n",
        "engine = create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4PIf1Z0bzjN"
      },
      "source": [
        "Step 2: Fetch Tables and Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL_1M2PSb1xT"
      },
      "outputs": [],
      "source": [
        "def fetch_table_metadata(engine):\n",
        "    inspector = inspect(engine)\n",
        "    tables = inspector.get_table_names()\n",
        "    metadata = {}\n",
        "    for table in tables:\n",
        "        columns = inspector.get_columns(table)\n",
        "        metadata[table] = {col['name']: col['type'] for col in columns}\n",
        "    return metadata\n",
        "\n",
        "metadata = fetch_table_metadata(engine)\n",
        "print(metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMLmswCgcCdY"
      },
      "source": [
        "Step 3: Convert User Question to SQL Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBJpdQf1cDR0"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Fetch the API key from Google Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize OpenAI client with the API key\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "def convert_question_to_sql(user_question, metadata):\n",
        "    schema_description = \"Database schema:\\n\"\n",
        "    for table, columns in metadata.items():\n",
        "        schema_description += f\"Table: {table}\\n\"\n",
        "        for column in columns:\n",
        "            schema_description += f\"  - {column} ({columns[column]})\\n\"\n",
        "\n",
        "    prompt = f\"{schema_description}\\nConvert the following question into SQL using precise table and column names and postgre sql syntax:\\n{user_question} Give only the code.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an SQL expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    sql_query = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Clean up the SQL query\n",
        "    sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac65sZOqcQOk"
      },
      "source": [
        "Step 4: Execute SQL Query and Explain Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coT7w7dhcRSz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def execute_sql_query(engine, sql_query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql(sql_query, connection)\n",
        "    return result\n",
        "\n",
        "def explain_results(user_question, result):\n",
        "    # Get the total count of matching rows\n",
        "    total_count = len(result)\n",
        "\n",
        "    # Extract column names and a sample row\n",
        "    columns = result.columns.tolist()\n",
        "    sample_row = result.head(5).iloc[0].tolist()\n",
        "\n",
        "    # Construct a sample string from the first row\n",
        "    sample_details = ', '.join([f\"{col}: {val}\" for col, val in zip(columns, sample_row)])\n",
        "\n",
        "    # Create a summary explanation\n",
        "    prompt = (f\"You asked: '{user_question}'\\n\"\n",
        "              f\"There are {total_count} results. \"\n",
        "              f\"{sample_details}\\n\"\n",
        "              \"Explain the result in simple terms.\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    explanation = response.choices[0].message.content.strip()\n",
        "    return explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHijdfIhDCj"
      },
      "source": [
        "Step 5: Main Workflow with User Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZXMzHdPhGsU"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Fetch metadata\n",
        "metadata = fetch_table_metadata(engine)\n",
        "\n",
        "# Prompt user for input\n",
        "user_question = input(\"Please enter your question: \")\n",
        "\n",
        "# Convert question to SQL query\n",
        "try:\n",
        "    sql_query = convert_question_to_sql(user_question, metadata)\n",
        "\n",
        "    # Execute SQL query and store results\n",
        "    result = execute_sql_query(engine, sql_query)\n",
        "\n",
        "    # Explain the results\n",
        "    explanation = explain_results(user_question, result)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\nFinal Output:\\n\")\n",
        "    print(f\"Your question was: {user_question}\\n\")\n",
        "    print(f\"Generated SQL Query:\\n{sql_query}\\n\")\n",
        "    print(\"SQL Query Result:\")\n",
        "    print(tabulate(result, headers='keys', tablefmt='psql'))\n",
        "    print(\"\\nExplanation of the Result:\")\n",
        "    print(explanation)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uTqgZBrEp4P"
      },
      "source": [
        "## Text2SQL OpenAI gpt-4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZnT76d1LgMQ"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, inspect\n",
        "\n",
        "# Database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create an engine\n",
        "engine = create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6YLTaA8EyZk"
      },
      "outputs": [],
      "source": [
        "def fetch_table_metadata(engine):\n",
        "    inspector = inspect(engine)\n",
        "    tables = inspector.get_table_names()\n",
        "    metadata = {}\n",
        "    for table in tables:\n",
        "        columns = inspector.get_columns(table)\n",
        "        metadata[table] = {col['name']: col['type'] for col in columns}\n",
        "    return metadata\n",
        "\n",
        "metadata = fetch_table_metadata(engine)\n",
        "print(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-nJ7F0DE2YJ"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Fetch the API key from Google Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize OpenAI client with the API key\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "def convert_question_to_sql(user_question, metadata):\n",
        "    schema_description = \"Database schema:\\n\"\n",
        "    for table, columns in metadata.items():\n",
        "        schema_description += f\"Table: {table}\\n\"\n",
        "        for column in columns:\n",
        "            schema_description += f\"  - {column} ({columns[column]})\\n\"\n",
        "\n",
        "    prompt = f\"{schema_description}\\nConvert the following question into SQL using precise table and column names and postgre sql syntax:\\n{user_question} Give only the code.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an SQL expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    sql_query = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Clean up the SQL query\n",
        "    sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdsGbJSEE6BS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def execute_sql_query(engine, sql_query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql(sql_query, connection)\n",
        "    return result\n",
        "\n",
        "def explain_results(user_question, result):\n",
        "    # Get the total count of matching rows\n",
        "    total_count = len(result)\n",
        "\n",
        "    # Extract column names and a sample row\n",
        "    columns = result.columns.tolist()\n",
        "    sample_row = result.head(5).iloc[0].tolist()\n",
        "\n",
        "    # Construct a sample string from the first row\n",
        "    sample_details = ', '.join([f\"{col}: {val}\" for col, val in zip(columns, sample_row)])\n",
        "\n",
        "    # Create a summary explanation\n",
        "    prompt = (f\"You asked: '{user_question}'\\n\"\n",
        "              f\"There are {total_count} results. \"\n",
        "              f\"{sample_details}\\n\"\n",
        "              \"Explain the result in simple terms.\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    explanation = response.choices[0].message.content.strip()\n",
        "    return explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkCA3W9nE8Dc"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Fetch metadata\n",
        "metadata = fetch_table_metadata(engine)\n",
        "\n",
        "# Prompt user for input\n",
        "user_question = input(\"Please enter your question: \")\n",
        "\n",
        "# Convert question to SQL query\n",
        "try:\n",
        "    sql_query = convert_question_to_sql(user_question, metadata)\n",
        "\n",
        "    # Execute SQL query and store results\n",
        "    result = execute_sql_query(engine, sql_query)\n",
        "\n",
        "    # Explain the results\n",
        "    explanation = explain_results(user_question, result)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\nFinal Output:\\n\")\n",
        "    print(f\"Your question was: {user_question}\\n\")\n",
        "    print(f\"Generated SQL Query:\\n{sql_query}\\n\")\n",
        "    print(\"SQL Query Result:\")\n",
        "    print(tabulate(result, headers='keys', tablefmt='psql'))\n",
        "    print(\"\\nExplanation of the Result:\")\n",
        "    print(explanation)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvXBshwQP_B5"
      },
      "source": [
        "# POC (Proof-of-Concept) with Join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2q-TlKpP_CA"
      },
      "source": [
        "## Clean database if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iZ6vmGAP_CA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, MetaData, Table\n",
        "\n",
        "# Set the database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Function to drop specified tables from the database using MetaData and Table\n",
        "def drop_tables(engine, table_names):\n",
        "    meta = MetaData()\n",
        "    meta.reflect(bind=engine)\n",
        "    with engine.connect() as connection:\n",
        "        for table_name in table_names:\n",
        "            if table_name in meta.tables:\n",
        "                table = Table(table_name, meta)\n",
        "                table.drop(engine, checkfirst=True)\n",
        "\n",
        "# List of tables to drop\n",
        "tables_to_drop = ['mock_data', 'sentiment']\n",
        "\n",
        "# Drop the tables\n",
        "drop_tables(engine, tables_to_drop)\n",
        "\n",
        "# Optional: Verify that the tables have been dropped\n",
        "def verify_tables_dropped(engine, table_names):\n",
        "    meta = MetaData()\n",
        "    meta.reflect(bind=engine)\n",
        "    existing_tables = meta.tables.keys()\n",
        "    return [table for table in table_names if table not in existing_tables]\n",
        "\n",
        "dropped_tables = verify_tables_dropped(engine, tables_to_drop)\n",
        "print(f\"Dropped tables: {dropped_tables}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp1E349zP_CA"
      },
      "source": [
        "## Breakdown the df in 2 tables for join demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLGA3TbP_CA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Assuming df is your original dataframe\n",
        "\n",
        "# Step 1: Create a 'unique_id' column\n",
        "df['unique_id'] = df.index + 1\n",
        "\n",
        "# Step 2: Create mock_data_to_sql and sentiment_to_sql dataframes\n",
        "mock_data_to_sql = df[['unique_id', 'Order ID', 'Investor ID', 'Investor Name', 'Region', 'Territory/Country',\n",
        "                       'Type', 'Firm (mm)', 'Alloc Firm (mm)', 'Limit Security', 'Spread', 'Hedge/Switch',\n",
        "                       'Modified', 'Created', 'Deal', 'Feedback']]\n",
        "\n",
        "sentiment_to_sql = df[['unique_id', 'flair_sentiment', 'flair_score']]\n",
        "\n",
        "# Step 3: Import dataframes into the SQL database\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Function to load data from the database\n",
        "def load_data_from_db(query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql_query(query, connection)\n",
        "    return result\n",
        "\n",
        "# Write mock_data_to_sql to the database as 'mock_data'\n",
        "mock_data_to_sql.to_sql('mock_data', engine, if_exists='replace', index=False)\n",
        "\n",
        "# Write sentiment_to_sql to the database as 'sentiment'\n",
        "sentiment_to_sql.to_sql('sentiment', engine, if_exists='replace', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aus6j_-XP_CA"
      },
      "outputs": [],
      "source": [
        "get_all_tables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNqlmo-P_CA"
      },
      "source": [
        "## Implement Text2SQL OpenAI gpt-4o model to new tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlstDlrJP_CA"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, inspect\n",
        "\n",
        "# Database URL\n",
        "DATABASE_URL = 'postgresql+psycopg2://thodoris:B4AqjEYBhDPXDHmuSW8MYgfdPp5Nob88@dpg-cpmtb4g8fa8c73aoakig-a.frankfurt-postgres.render.com/capstone_fs'\n",
        "\n",
        "# Create an engine\n",
        "engine = create_engine(DATABASE_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIr6RSxlP_CA"
      },
      "outputs": [],
      "source": [
        "def fetch_table_metadata(engine):\n",
        "    inspector = inspect(engine)\n",
        "    tables = inspector.get_table_names()\n",
        "    metadata = {}\n",
        "    for table in tables:\n",
        "        columns = inspector.get_columns(table)\n",
        "        metadata[table] = {col['name']: col['type'] for col in columns}\n",
        "    return metadata\n",
        "\n",
        "metadata = fetch_table_metadata(engine)\n",
        "print(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh2aSNOaP_CB"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Fetch the API key from Google Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize OpenAI client with the API key\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "def convert_question_to_sql(user_question, metadata):\n",
        "    schema_description = \"Database schema:\\n\"\n",
        "    for table, columns in metadata.items():\n",
        "        schema_description += f\"Table: {table}\\n\"\n",
        "        for column in columns:\n",
        "            schema_description += f\"  - {column} ({columns[column]})\\n\"\n",
        "\n",
        "    prompt = f\"{schema_description}\\nConvert the following question into SQL using precise table and column names and postgre sql syntax:\\n{user_question} Always try to find the most relevant tables and columns. Keep values in lowercase. Give only the code. Join tables on unique id if required.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an SQL expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    sql_query = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Clean up the SQL query\n",
        "    sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwIpg5FFP_CB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def execute_sql_query(engine, sql_query):\n",
        "    with engine.connect() as connection:\n",
        "        result = pd.read_sql(sql_query, connection)\n",
        "    return result\n",
        "\n",
        "def explain_results(user_question, result):\n",
        "    # Get the total count of matching rows\n",
        "    total_count = len(result)\n",
        "\n",
        "    # Check if the result DataFrame is empty\n",
        "    if total_count == 0:\n",
        "        return f\"You asked: '{user_question}'\\nThere are no results matching your query.\"\n",
        "\n",
        "    # Extract column names and a sample row\n",
        "    columns = result.columns.tolist()\n",
        "    sample_row = result.head(5).iloc[0].tolist()\n",
        "\n",
        "    # Construct a sample string from the first row\n",
        "    sample_details = ', '.join([f\"{col}: {val}\" for col, val in zip(columns, sample_row)])\n",
        "\n",
        "    # Create a summary explanation\n",
        "    prompt = (f\"You asked: '{user_question}'\\n\"\n",
        "              f\"There are {total_count} results. \"\n",
        "              f\"{sample_details}\\n\"\n",
        "              \"Explain the result in simple terms without using. Use more professional language.\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    explanation = response.choices[0].message.content.strip()\n",
        "    return explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpPmvJcmP_CB"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Fetch metadata\n",
        "metadata = fetch_table_metadata(engine)\n",
        "\n",
        "# Prompt user for input\n",
        "user_question = input(\"Please enter your question: \")\n",
        "user_question = user_question.lower()\n",
        "\n",
        "# Convert question to SQL query\n",
        "try:\n",
        "    sql_query = convert_question_to_sql(user_question, metadata)\n",
        "\n",
        "    # Execute SQL query and store results\n",
        "    result = execute_sql_query(engine, sql_query)\n",
        "\n",
        "    # Explain the results\n",
        "    explanation = explain_results(user_question, result)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\nFinal Output:\\n\")\n",
        "    print(f\"Your question was: {user_question}\\n\")\n",
        "    print(f\"Generated SQL Query:\\n{sql_query}\\n\")\n",
        "    print(\"SQL Query Result:\")\n",
        "    print(tabulate(result, headers='keys', tablefmt='psql'))\n",
        "    print(\"\\nExplanation of the Result:\")\n",
        "    print(explanation)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "tI5lflgpvGfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmNlwCdu1dIx"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.address=localhost &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "2UUvMnc1msyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "hoKAh1DLmvXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "69DIWRzxF2Pv",
        "TCZBsbZLeeAW",
        "eV0zHTEDeT23",
        "5UExRrAg6OnA",
        "QIwVDDITIXMc",
        "hJL5qPz0JrkG",
        "rOMYbo3hKawX",
        "MAkZA2g8VvGr",
        "WrN_4k7SQvo1",
        "eNfVsbfNPMTG",
        "f_cgFD8QQ8Up",
        "CUUJyMSkfSUD",
        "iG2_gSKCR7nc",
        "iclMY3Lq6ds1",
        "q7LYamEnRSt_",
        "BZYrxM59STCa",
        "OCz6mhK2beqC",
        "oKQqwq3_hWra",
        "DMfmKQ_1hgQ_",
        "IrWZlQ76ib-g",
        "K9JQBPPbitKE",
        "Ilqf7xze_N1k",
        "un9EV4FplLmb",
        "12tfFIDnoZak",
        "4kuPnXBI1qZ-",
        "hxy3vnIjnGx8",
        "m5bx_UBjv35r",
        "vfnbc-ehzSDw",
        "8g0PQIkb3CaT",
        "cEZOhEzbIA_I",
        "USeTR2KXEMKB",
        "_uTqgZBrEp4P",
        "qvXBshwQP_B5",
        "M2q-TlKpP_CA",
        "bp1E349zP_CA",
        "yHNqlmo-P_CA",
        "tI5lflgpvGfu"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}